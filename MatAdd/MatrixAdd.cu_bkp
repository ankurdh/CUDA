#include<stdio.h>
#include<stdlib.h>

__global__ void matAdd(int *matrixA, int *matrixB, int *matrixC, int matSize)
{
    int threadCol = blockIdx.x * blockDim.x + threadIdx.x;
    int threadRow = blockIdx.y * blockDim.y + threadIdx.y;
   
    int indexOfMatrix = threadCol + threadRow * matSize;

    if(threadCol < matSize && threadRow < matSize)
        matrixC[indexOfMatrix] = matrixA[indexOfMatrix] + matrixB[indexOfMatrix];      

}

void printMatrix(int *matrix, int size, char * matrixName)
{

    if(size > 10)
      return;

    int i = 0;
    printf("Printing Matrix: %s\n", matrixName);
    for( ; i < size * size ; i ++)
    {
        if(i % size == 0) 
            printf("\n");
            
        printf("%-3d  ", matrix[i]);
    }
    
    printf("\n\n");
}

void checkError(cudaError_t error, char * function)
{

        if(error != cudaSuccess)
        {
                printf("\"%s\" has a problem with error code %d and desc: %s\n", function, error, cudaGetErrorString(error));
                exit(-1);
        }
}


bool checkIfMatricesEqual(int * mat1, int * mat2, int matSize)
{
    int i = 0;
    for( ; i < matSize; i++)
       if(mat1[i] != mat2[i])
           return false;

    return true;
}

void readValue(int *value, char * msg)
{
    pritnf("%s: ", msg);
    scanf("%d", value);
}


int main()
{

   //Have some variables required for loop counters.
   int i;

   //have variables for threads per block, number of blocks.
   int threadsPerBlock, blocksPerThread;

   //program variables
   int matrixSize = 0;
   size_t size;                     //variable to have the size of arrays on device
   int *matA, *matB, *matC, *matCFromGPU;   //matrices for host
   int *gpuMatA, *gpuMatB, *gpuMatC;            //matrices for Device

   printf("Enter the size of the matrix: ");
   scanf("%d", &matrixSize);

   //calculate the size required on GPU
   size = matrixSize * matrixSize * sizeof(int);

   matA = (int *)malloc(matrixSize * sizeof(int) * matrixSize);
   matB = (int *)malloc(matrixSize * sizeof(int) * matrixSize);
   matC = (int *)malloc(matrixSize * sizeof(int) * matrixSize);
   matCFromGPU = (int *)malloc(matrixSize * sizeof(int) * matrixSize);

   for(i = 0 ; i < matrixSize * matrixSize; i ++)
         matA[i] = matB[i] = (i*2)%10;

   //printMatrix(matA, matrixSize, "Matrix A");
   //printMatrix(matB, matrixSize, "Matrix B");

   for(i = 0 ; i < matrixSize * matrixSize; i ++)
           matC[i] = matA[i] + matB[i];

   printMatrix(matC, matrixSize, "Summation Matrix");

   //allocate memory on GPU
   checkError(cudaMalloc((void**)&gpuMatA, size), "Malloc for Matrix A");
   checkError(cudaMalloc((void**)&gpuMatB, size), "Malloc for Matrix B");
   checkError(cudaMalloc((void**)&gpuMatC, size), "Malloc for Matrix C");
   
   //copy the matrix A and matrix B
   checkError(cudaMemcpy(gpuMatA, matA, size, cudaMemcpyHostToDevice), "Matrix A Copy");
   checkError(cudaMemcpy(gpuMatB, matB, size, cudaMemcpyHostToDevice), "Matrix B Copy");

   //create a proper grid block using dim3
   readValue(thread
 
   dim3 blocks(4, 4);							//have 4x4 blocks
   dim3 grid((matrixSize + blocks.x - 1/blocks.x), (matrixSize + blocks.y - 1/blocks.y));

   //call the kernels to execute
   matAdd<<<grid, blocks>>>(gpuMatA, gpuMatB, gpuMatC, matrixSize);   

   //copy the result back into host memory
   checkError(cudaMemcpy(matCFromGPU, gpuMatC, size, cudaMemcpyDeviceToHost), "Matrix C Copy from device to Host");

   if(checkIfMatricesEqual(matC, matCFromGPU, matrixSize))
      printf("Kernels correct!\n");
   else
      printf("Kernel logic wrong!\n");

   printMatrix(matCFromGPU, matrixSize, "Summation Matrix from GPU");

   free(matA);
   free(matB);
   free(matC);
   free(matCFromGPU);

   return 0;
}
